# -*- coding: utf-8 -*-
"""Credit card Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LeF8DQMQMphdANUsv_lfqZtEPNK9vRvf

# Data Preprocessing

dataset : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

## importing libraries and dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Install kaggle API
! pip install -q kaggle

#upload kaggle API key to colab notebook
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/

# disable API key
! chmod 600 /root/.kaggle/kaggle.json

# import the dataset
! kaggle datasets download -d mlg-ulb/creditcardfraud

# unzipping the dataset
! unzip -q /content/creditcardfraud.zip

"""## Data Exploration"""

dataset = pd.read_csv('/content/creditcard.csv')

dataset.head()

dataset.shape

dataset.columns

dataset.info()

# statistical summary
dataset.describe()

"""## Dealing with missing values"""

dataset.isnull().values.any()

dataset.isnull().values.sum()

"""## Encoding categorical data"""

dataset.select_dtypes(include  ='object').columns

len(dataset.select_dtypes(include  ='object').columns)

"""## Count plot"""

sns.countplot(x = 'Class', data = dataset)

# non fraud transactions
(dataset.Class == 0).sum()

# fraud transactions
(dataset.Class == 1).sum()

"""## Correlation matrix and heatmap"""

dataset_2 =dataset.drop(columns = 'Class')

dataset_2.corrwith(dataset['Class']).plot.bar(
    figsize = (16,9), title = 'Correlation with Class' ,grid =True
)

corr = dataset.corr()

plt.figure(figsize = (16,9))
ax = sns.heatmap(corr, annot =True)

"""## Splitting the Dataset"""

dataset.head()

# matrix of features/ independent variables
x = dataset.drop(columns ='Class')

# target variables / dependent variables
y = dataset['Class']

from sklearn.model_selection import train_test_split
x_train, x_test,y_train,y_test = train_test_split(x,y,test_size =0.2, random_state =0)

x_train.shape

x_test.shape

y_train.shape

y_test.shape

"""## Feature **scaling**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

x_test

"""# Building the model

## Logistic regression
"""

from sklearn.linear_model import LogisticRegression
classifier_lr = LogisticRegression(random_state=0)
classifier_lr.fit(x_train,y_train)

y_pred = classifier_lr.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

acc = accuracy_score(y_test,y_pred)

acc

cm = confusion_matrix(y_test,y_pred)

cm

"""## Random forest"""

from sklearn.ensemble import RandomForestClassifier
classifier_rf = RandomForestClassifier(random_state =0)
classifier_rf.fit(x_train,y_train)

y_pred =classifier_rf.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

acc = accuracy_score(y_test,y_pred)

acc

cm = confusion_matrix(y_test,y_pred)

cm

"""## XGBoost Classifier"""

from xgboost import XGBClassifier
classifier_xgb = XGBClassifier(random_state =0)
classifier_xgb.fit(x_train,y_train)

y_pred =classifier_xgb.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

acc = accuracy_score(y_test,y_pred)

acc

cm = confusion_matrix(y_test,y_pred)

cm

"""# Final Model (Random Forest)"""

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(random_state =0)
classifier.fit(x_train,y_train)

y_pred =classifier_rf.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

acc = accuracy_score(y_test,y_pred)

acc

cm = confusion_matrix(y_test,y_pred)

cm

"""# Predicting a single observation"""

dataset.head()

dataset.shape

single_obs = [[0.0,-1.3,2.1,1.3,-0.3,0.46,0.23,0.09,0.36,0.09,-0.55,-0.6,1.1,0.8,1.1,0.8,0.6,0.5,0.3,1.1,-1.1,-0.8,-1.3,1.0,0.58,-0.6,0.08,0.06,-0.09,14]]

single_obs

classifier.predict(sc.transform(single_obs))

